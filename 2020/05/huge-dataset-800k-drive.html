<!DOCTYPE html>
<html lang="english">

<head>
    <meta charset="utf-8">
  <meta http-equiv="Content-Type" content="text/html" charset="UTF-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />


  <title>Working with huge datasets, 800K+ files in Google Colab and Google Drive</title>


  <meta name="HandheldFriendly" content="True" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="referrer" content="origin" />
  <meta name="generator" content="Pelican" />
  <link href="/" rel="canonical" />

  <!-- Feed -->

  <link href="/theme/css/style.css" type="text/css" rel="stylesheet" />

  <!-- Code highlight color scheme -->
      <link href="/theme/css/code_blocks/github.css" rel="stylesheet">

    <!-- CSS specified by the user -->


    <link href="/assets/css/myblog.css" type="text/css" rel="stylesheet" />

  <!-- Custom fonts -->
  <link href='https://fonts.googleapis.com/css?family=Montserrat:400,300' rel='stylesheet' type='text/css' />
  <link href="https://fonts.googleapis.com/css?family=Lato" rel="stylesheet" type="text/css" />

  <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
  <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
  <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
    <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
  <![endif]-->


  <link href="/2020/05/huge-dataset-800k-drive.html" rel="canonical" />

    <meta name="description" content="This experience is about the problems i faced when doing an assignment that involved working with large amount of files 800K images for...">

    <meta name="author" content="satyajit-ghana">

    <meta name="tags" content="google colab">
    <meta name="tags" content="dataset">
    <meta name="tags" content="800k files">




<!-- Open Graph -->
<meta property="og:site_name" content="Satyajit Ghana"/>
<meta property="og:title" content="Working with huge datasets, 800K+ files in Google Colab and Google Drive"/>
<meta property="og:description" content="This experience is about the problems i faced when doing an assignment that involved working with large amount of files 800K images for..."/>
<meta property="og:locale" content="en_US"/>
<meta property="og:url" content="/2020/05/huge-dataset-800k-drive.html"/>
<meta property="og:type" content="article"/>
<meta property="article:published_time" content="2020-05-05 10:20:00+05:30"/>
<meta property="article:modified_time" content="2020-05-05 19:30:00+05:30"/>
<meta property="article:author" content="/author/satyajit-ghana">
<meta property="article:section" content="blog"/>
<meta property="article:tag" content="google colab"/>
<meta property="article:tag" content="dataset"/>
<meta property="article:tag" content="800k files"/>
<meta property="og:image" content="/theme/images/post-bg.jpg">

<!-- Twitter Card -->

<script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Article",
  "name": "Working with huge datasets, 800K+ files in Google Colab and Google Drive",
  "headline": "Working with huge datasets, 800K+ files in Google Colab and Google Drive",
  "datePublished": "2020-05-05 10:20:00+05:30",
  "dateModified": "2020-05-05 19:30:00+05:30",
  "author": {
    "@type": "Person",
    "name": "satyajit-ghana",
    "url": "/author/satyajit-ghana"
  },
  "image": "/theme/images/post-bg.jpg",
  "url": "/2020/05/huge-dataset-800k-drive.html",
  "description": "This experience is about the problems i faced when doing an assignment that involved working with large amount of files 800K images for..."
}
</script>
</head>
<!-- TODO : Body class -->
<body class="home-template">

<nav id="menu">
  <a class="close-button">Close</a>
  <div class="nav-wrapper">
    <p class="nav-label">Menu</p>
    <ul>

              <li role="presentation"><a href="/pages/about/">About</a></li>

    </ul>
  </div>
</nav>
    <!-- Progressbar -->
    <div class="progress-container">
        <span class="progress-bar"></span>
    </div>

    <!-- Page Header -->
    <!-- Set your background image for this header on the line below. -->
    <header id="post-header" class="has-cover">
      <div class="inner">
        <nav id="navigation">
            <span id="home-button" class="nav-button">
                <a class="home-button" href="/" title="Home"><i class="ic ic-arrow-left"></i> Home</a>
            </span>
          <span id="menu-button" class="nav-button">
            <a class="menu-button"><i class="ic ic-menu"></i> Menu</a>
          </span>
        </nav>
        <h1 class="post-title">Working with huge datasets, 800K+ files in Google Colab and Google Drive</h1>
        <!-- TODO : Proper class for headline -->
        <span class="post-meta">
                <a href="/author/satyajit-ghana">Satyajit Ghana</a>
            | <time datetime="05 May 2020">05 May 2020</time>
        </span>
        <!-- TODO : Modified check -->
            <span class="post-meta"> | Updated on 05 May 2020</span>
            <div class="post-cover cover" style="background-image: url('/theme/images/post-bg.jpg')">
      </div>
    </header>

  <section id="wrapper">
    <a class="hidden-close"></a>

    <!-- Post content -->
    <main class="content" role="main">
        <article class="post">
        <div class="inner">
            <section class="post-content">
                <h1>Working with huge datasets, 800K+ files in Google Colab and Google Drive</h1>
<p><img alt="head" src="/2020/05/assets/head.png">
<center><em>colab + drive</em></center></p>
<p>Recently i had to make a dataset of 400K images + 400K image masks, and then had to train them on a Deep Neural Network using the Google Colab free Tesla P100 GPUs, this article is about the journey i had to go through, and learnt quite some nifty ways people have solved this issue.</p>
<p>Starting off, 800K files seemed pretty simple, i wrote a simple script for my dataset generator, that created 1kb jpeg each file and stored them to my SSHD, it took about ~17 mins to do so. Okay now that i know everything worked on my local machine, how about i put them into Google Drive.</p>
<p>Why am i trying to do this on google drive and colab ? i need to train a depth estimation model, that will ingest all this data and train, Google Colab provides them free sweeeeet Tesla P100s that are so damn goood :* , and my puny little 1050Ti is no match to it, if i have my dataset on google drive, its easy to mount it in colab and train the network, and periodically save the model directly on drive.</p>
<p>Hereâ€™s a snippet of my code for creating my dataset:</p>
<script src="https://gist.github.com/satyajitghana/fc6642107f0a4049a78b072d300588e9.js"></script>

<p>This code produced 800k+ files with total size of about ~2Gb, which is relatively small.</p>
<p><img src="/2020/05/assets/zip_size.png" style="display: block; margin: 0 auto; max-width: 50%; width: auto " /></p>
<p>So what now ? here were the options i tried</p>
<h2>1. Upload the entire folder to google drive containing the 800k+ images</h2>
<p>The result was that it will take an eternity to upload them, it takes a hell lot of time to do this, you could also use the Google Drive Sync, which iâ€™ve used before for huge datasets, but for my current case, this was also way slow, i couldnâ€™t wait for more than 8 hours, since my assignment deadline was closing in. This was a complete no no.</p>
<h2>2. Zip the dataset folder, Upload to GDrive and then unzip</h2>
<p>This seems that something that might work right ?</p>
<p>wrong ! although i tried to use .zip and .tar, both without any compression, uploaded to google drive as well, but the problem was unzipping it.</p>
<p>Google Drive has this ZipExtractor, which didnâ€™t work for me, it went out of memory</p>
<p><img alt="page-unresponsive" src="/2020/05/assets/page-unresponsive.png"></p>
<p>So why not try mounting the google drive on colab and then running unzip on it ? well . . . same story, it takes a damn long time to extract, something that i learned was that Google Drive limits your number of I/O operations performed on the drive using the Python GDrive API, it gets slower, my estimate was it would take about ~7 hours to unzip the entire dataset on google drive, and then i had to make sure it was extracted completely, also making sure that the colab runtime doesnâ€™t disconnect, which is a big pain in the a anyways ðŸ˜Œ.</p>
<h2>3. Create the dataset directly on Google Colab and write the files on drive</h2>
<p>One reason why the I/O operations were getting slower was because Drive will index your files and create thumbnail previews of them. You what else was really frustrating ? deleting the created dataset, i couldnâ€™t use !rm -rf , drive was frequently getting disconnected, this also means a flag for you, your account might get suspended if you continue to attack the drive i/o like this.</p>
<p><img alt="This is damn long time for a single background image to process, each of these BG is creating 200*20 images" src="/2020/05/assets/long-time.png">
<center>
<em>This is damn long time for a single background image to process, each of these BG is creating 200x20 images</em>
</center></p>
<p>So i needed a solution that doesnâ€™t work with too many files in drive at once, and makes sure that there are not too many i/o operations happening at a time, and drive doesnâ€™t have to create thumbnail preview of my images.</p>
<h2>4. Maybe use threads ?</h2>
<p>ðŸ˜‚ This is useless, you get 2 CPU cores in colab, and there isnâ€™t any benefit of using multiprocessing here, same issue, an estimate of ~5 hours to create the dataset.</p>
<blockquote>
<h1>Hmm . . . so what worked ! ?</h1>
</blockquote>
<h2>Create the Dataset on Google Drive, directly into a .zip/.tar file ðŸ¥³ðŸŽŠ</h2>
<p>Python has a <a href="https://docs.python.org/3/library/zipfile.html#module-zipfile">ZipFile</a> package that can help you create .zip/.tar files and directly add files into it, just like a<em> directory</em> !, and moreover .zip files stays as single file, Google Drive doesnâ€™t complain about working with too many files, and it doesnâ€™t have to create those thumbnail previews.</p>
<p>Another advantage is that now you can directly read from the zip file while training your model as well, no need to unzip it and then train.</p>
<p>Awesome !! , so how do i do this ?</p>
<p>I modified my code to this</p>
<script src="https://gist.github.com/satyajitghana/7a0887bdf0825a497c785a2c7f247be3.js"></script>

<p>And it took about and hour to finish, but the good thing is, now i can easily download the zip, i donâ€™t have to manually go to the folder in gdrive and then wait for it to zip, which will again take a long time. Also itâ€™s very easy to share my .zip file with others.</p>
<p>Lessons learnt:</p>
<ul>
<li>always work with your huge datasets in batches !</li>
<li>save your work in google drive periodically, use .zip files if you work with huge datasets, <strong>consider splitting them into parts if possible</strong></li>
<li>you might need to use the garbage collector in python to clear up memory</li>
</ul>
<p>I was finally able to create my dataset, well . . . now i have to run a depth estimation model on all the images, thatâ€™s gonna take a while . . . â˜•</p>
<p><img alt="Depth Estimation model run on my dataset" src="https://cdn-images-1.medium.com/max/2000/1*40x2gVZjU7WAou3d77BnPw.png">
<center>
<em>Depth Estimation model run on my dataset</em>
</center></p>
<p>ðŸ˜‚ Let's not comment on my bad model, the point is ZipFile works ! and works great for datasets that have a huge number of files.</p>
<p>Here are some tutorials on ZipFile</p>
<ul>
<li><a href="https://pymotw.com/2/zipfile/">https://pymotw.com/2/zipfile/</a></li>
<li><a href="https://www.geeksforgeeks.org/working-zip-files-python/">https://www.geeksforgeeks.org/working-zip-files-python/</a></li>
</ul>
<h2><strong>Thatâ€™s all Folks!</strong></h2>
<p>This is my first medium article, hope you, the reader like it ðŸ˜ŠðŸ˜€</p>
            </section>

            <section class="post-info">
                <div class="post-share">
                    <a class="twitter" href="https://twitter.com/share?text=Working with huge datasets, 800K+ files in Google Colab and Google Drive&amp;url=/2020/05/huge-dataset-800k-drive.html" onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
                    <i class="ic ic-twitter"></i><span class="hidden">Twitter</span>
                    </a>
                    <a class="facebook" href="https://www.facebook.com/sharer/sharer.php?u=/2020/05/huge-dataset-800k-drive.html" onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;">
                    <i class="ic ic-facebook"></i><span class="hidden">Facebook</span>
                    </a>
                    <a class="googleplus" href="https://plus.google.com/share?url=/2020/05/huge-dataset-800k-drive.html" onclick="window.open(this.href, 'google-plus-share', 'width=490,height=530');return false;">
                    <i class="ic ic-googleplus"></i><span class="hidden">Google+</span>
                    </a>
                    <div class="clear"></div>
                </div>

                <aside class="post-tags">
<a href="/tag/google-colab">google colab</a><a href="/tag/dataset">dataset</a><a href="/tag/800k-files">800k files</a>                </aside>

                <div class="clear"></div>

                <aside class="post-author">


                        <figure class="post-author-avatar">
                            <img src="/assets/images/avatar.jpg" alt="Satyajit Ghana" />
                        </figure>
                    <div class="post-author-bio">
                        <h4 class="post-author-name"><a href="/author/satyajit-ghana">Satyajit Ghana</a></h4>
                            <p class="post-author-about">idhar bhi ek catchy bio likhna hai</p>
                            <span class="post-author-location"><i class="ic ic-location"></i> Bangalore</span>
                            <span class="post-author-website"><a href="http://github.com/satyajitghana"><i class="ic ic-link"></i> Website</a></span>
                        <!-- Social linkes in alphabet order. -->
                            <span class="post-author-github"><a target="_blank" href="https://github.com/satyajitghana"><i class="ic ic-link"></i> GitHub</a></span>
                            <span class="post-author-linkedin"><a target="_blank" href="https://www.linkedin.com/in/satyajitghana"><i class="ic ic-link"></i> LinkedIn</a></span>
                    </div>
                    <div class="clear"></div>
                </aside>

                </section>


                <aside class="post-nav">
                    <div class="clear"></div>
                </aside>

            </div>
        </article>
    </main>
      <!-- TODO : Body class -->
    <div id="body-class" style="display: none;" class=""></div>

    <footer id="footer">
      <div class="inner">
        <section class="credits">


          <span class="credits-theme">Theme <a href="https://github.com/arulrajnet/attila" rel="nofollow">Attila</a></span>
          <span class="credits-software">Published with <a href="https://github.com/getpelican/pelican" rel="nofollow">Pelican</a></span>
        </section>
      </div>
    </footer>
  </section>

  <script type="text/javascript" src="/theme/js/script.js"></script>

</body>
</html>
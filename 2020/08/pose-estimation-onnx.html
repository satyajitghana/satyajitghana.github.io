<!DOCTYPE html>
<html lang="english">

<head>
    <meta charset="utf-8">
  <meta http-equiv="Content-Type" content="text/html" charset="UTF-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />


  <title>Human Pose Estimation and Quantization of PyTorch to ONNX Models — A Detailed Guide</title>


  <meta name="HandheldFriendly" content="True" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="referrer" content="origin" />
  <meta name="generator" content="Pelican" />
  <link href="/" rel="canonical" />

  <!-- Feed -->

  <link href="/theme/css/style.css" type="text/css" rel="stylesheet" />

  <!-- Code highlight color scheme -->
      <link href="/theme/css/code_blocks/github.css" rel="stylesheet">

    <!-- CSS specified by the user -->


    <link href="/assets/css/myblog.css" type="text/css" rel="stylesheet" />

  <!-- Custom fonts -->
  <link href='https://fonts.googleapis.com/css?family=Montserrat:400,300' rel='stylesheet' type='text/css' />
  <link href="https://fonts.googleapis.com/css?family=Lato" rel="stylesheet" type="text/css" />

  <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
  <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
  <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
    <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
  <![endif]-->


  <link href="/2020/08/pose-estimation-onnx.html" rel="canonical" />

    <meta name="description" content="The story begins with a assignment given to me that needed me to deploy a Monocular Single Human Pose Estimation model on AWS Lambda. Me...">

    <meta name="author" content="satyajit-ghana">

    <meta name="tags" content="hpe">
    <meta name="tags" content="pytorch">
    <meta name="tags" content="onnx">
    <meta name="tags" content="quantization">




<!-- Open Graph -->
<meta property="og:site_name" content="Satyajit Ghana"/>
<meta property="og:title" content="Human Pose Estimation and Quantization of PyTorch to ONNX Models — A Detailed Guide"/>
<meta property="og:description" content="The story begins with a assignment given to me that needed me to deploy a Monocular Single Human Pose Estimation model on AWS Lambda. Me..."/>
<meta property="og:locale" content="en_US"/>
<meta property="og:url" content="/2020/08/pose-estimation-onnx.html"/>
<meta property="og:type" content="article"/>
<meta property="article:published_time" content="2020-08-25 10:20:00+05:30"/>
<meta property="article:modified_time" content="2020-08-30 19:30:00+05:30"/>
<meta property="article:author" content="/author/satyajit-ghana">
<meta property="article:section" content="tutorial"/>
<meta property="article:tag" content="hpe"/>
<meta property="article:tag" content="pytorch"/>
<meta property="article:tag" content="onnx"/>
<meta property="article:tag" content="quantization"/>
<meta property="og:image" content="/theme/images/post-bg.jpg">

<!-- Twitter Card -->

<script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Article",
  "name": "Human Pose Estimation and Quantization of PyTorch to ONNX Models — A Detailed Guide",
  "headline": "Human Pose Estimation and Quantization of PyTorch to ONNX Models — A Detailed Guide",
  "datePublished": "2020-08-25 10:20:00+05:30",
  "dateModified": "2020-08-30 19:30:00+05:30",
  "author": {
    "@type": "Person",
    "name": "satyajit-ghana",
    "url": "/author/satyajit-ghana"
  },
  "image": "/theme/images/post-bg.jpg",
  "url": "/2020/08/pose-estimation-onnx.html",
  "description": "The story begins with a assignment given to me that needed me to deploy a Monocular Single Human Pose Estimation model on AWS Lambda. Me..."
}
</script>
</head>
<!-- TODO : Body class -->
<body class="home-template">

<nav id="menu">
  <a class="close-button">Close</a>
  <div class="nav-wrapper">
    <p class="nav-label">Menu</p>
    <ul>

              <li role="presentation"><a href="/pages/about/">About</a></li>

    </ul>
  </div>
</nav>
    <!-- Progressbar -->
    <div class="progress-container">
        <span class="progress-bar"></span>
    </div>

    <!-- Page Header -->
    <!-- Set your background image for this header on the line below. -->
    <header id="post-header" class="has-cover">
      <div class="inner">
        <nav id="navigation">
            <span id="home-button" class="nav-button">
                <a class="home-button" href="/" title="Home"><i class="ic ic-arrow-left"></i> Home</a>
            </span>
          <span id="menu-button" class="nav-button">
            <a class="menu-button"><i class="ic ic-menu"></i> Menu</a>
          </span>
        </nav>
        <h1 class="post-title">Human Pose Estimation and Quantization of PyTorch to ONNX Models — A Detailed Guide</h1>
        <!-- TODO : Proper class for headline -->
        <span class="post-meta">
                <a href="/author/satyajit-ghana">Satyajit Ghana</a>
            | <time datetime="25 Aug 2020">25 Aug 2020</time>
        </span>
        <!-- TODO : Modified check -->
            <span class="post-meta"> | Updated on 30 Aug 2020</span>
            <div class="post-cover cover" style="background-image: url('/theme/images/post-bg.jpg')">
      </div>
    </header>

  <section id="wrapper">
    <a class="hidden-close"></a>

    <!-- Post content -->
    <main class="content" role="main">
        <article class="post">
        <div class="inner">
            <section class="post-content">
                <h1>Human Pose Estimation and Quantization of PyTorch to ONNX Models — A Detailed Guide</h1>
<p>The story begins with a assignment given to me that needed me to deploy a Monocular Single Human Pose Estimation model on AWS Lambda. Me being a student, i prefer to be in the free tier of Lambda, where we get about 3GB of RAM and 500MB storage, the storage is quite less, and i had troubles fitting everything in one lambda, so i thought of trying out ONNX instead of using PyTorch. So let’s see how HPE works and how i converted a PyTorch Model to ONNX and then Quantized it.</p>
<p>Buckle up, this is going to be a long story !</p>
<p>If TL DR; then just see the below colab notebook
<a href="https://github.com/satyajitghana/TSAI-DeepVision-EVA4.0-Phase-2/blob/master/05-HumanPoseEstimation-ONNX/HumanPoseEstimation_ONNX_Quant.ipynb"><strong>satyajitghana/TSAI-DeepVision-EVA4.0-Phase-2</strong>
<em>HumanPoseEstimation-PyTorch-ONNX-Quant</em>github.com</a>
<a href="https://colab.research.google.com/drive/1uFLEw-p9Syui0GoDMsZSIoyiCyILVoCO?usp=sharing"><strong>Google Colaboratory</strong>
<em>HumanPoseEstimation-PyTorch-ONNX-Quant</em>colab.research.google.com</a></p>
<h2>Monocular Human Pose Estimation</h2>
<p>Human pose estimation is the process of estimating the configuration of the body (pose) from a single, typically monocular, image. It can be applied to many applications such as action/activity recognition, action detection, human tracking, in movies and animation, virtual reality, human-computer interaction, video surveillance, medical assistance, self-driving, sports motion analysis, etc.</p>
<p>Broadly there are 4 HPE Methods</p>
<ul>
<li>Generative and Discriminative (3D Single Person)</li>
<li>Top Down and Bottom Up (Multi-Person)</li>
<li>Regression and Detection Based (Single Person)</li>
<li>One-Stage and Multi-Stage</li>
</ul>
<p>But in this story we will be using the Bottom Up Approach, i.e. we will be detecting the body parts (joints, limbs, or small template patches) and then joining them to create our human body.</p>
<p>The model i am referring to here is from the <a href="https://arxiv.org/pdf/1804.06208.pdf">this</a> Paper.</p>
<p><img alt="" src="https://cdn-images-1.medium.com/max/2000/1*NAEoj1gL_VGAQCmSRsCqqw.png"></p>
<p>The paper describes and compares their model to SOTA hpe models that use the Hourglass model structure, the paper shows how even a very simple model, by adding deconv layers to the ResNet backbone can also give pretty good results. The code for this ResNet backbone PoseNet can be found <a href="https://github.com/microsoft/human-pose-estimation.pytorch">here</a>.</p>
<p><img alt="Simple Pose Benchmark" src="https://cdn-images-1.medium.com/max/2000/1*7cUfWGNb8KZvZQvNV4aiXw.png"><em>Simple Pose Benchmark</em></p>
<p>As you can see that a simple conv network has got a pretty good accuracy.</p>
<p>Enough of the model talk ! (i recommend reading the beautiful paper i referred above), Now let’s get to do some inferencing on the model and see what it outputs. Throughout this story i will be using <a href="http://colab.research.google.com">Google Colab</a> for running everything.</p>
<p>Start by cloning the <a href="https://github.com/microsoft/human-pose-estimation.pytorch">human-pose-estimation.pytorch</a> repository</p>
<div class="highlight"><pre><span></span><code><span class="err">! git clone https://github.com/microsoft/human-pose-estimation.pytorch &amp;&amp; cd human-pose-estimation.pytorch &amp;&amp; git checkout 18f1d0fa5b5db7fe08de640610f3fdbdbed8fb2f</span>
</code></pre></div>


<p>Add it to the sys.path so colab knows where the library is</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">sys</span>
<span class="k">if</span> <span class="s2">&quot;/content/human-pose-estimation.pytorch/lib/&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="p">:</span>
    <span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;/content/human-pose-estimation.pytorch/lib/&quot;</span><span class="p">)</span>
</code></pre></div>


<p>Import everything !</p>
<script src="https://gist.github.com/satyajitghana/7d84e290421a74327e02c79777126555.js"></script>

<p>For this story we will use the ResNet50 model trained on 256x256 images of the <a href="http://human-pose.mpi-inf.mpg.de/">MPII Dataset</a>, it has 16 human body points. All of the MPII models can be found below
<a href="https://drive.google.com/drive/folders/1g_6Hv33FG6rYRVLXx1SZaaHj871THrRW"><strong>pose_mpii - Google Drive</strong>
<em>Edit description</em>drive.google.com</a></p>
<p>set the CONFIG_FILE and MODEL_PATH variables appropriately</p>
<div class="highlight"><pre><span></span><code><span class="n">CONFIG_FILE</span> <span class="o">=</span> <span class="s1">&#39;/content/human-pose-estimation.pytorch/experiments/mpii/resnet50/256x256_d256x3_adam_lr1e-3.yaml&#39;</span>

<span class="n">MODEL_PATH</span> <span class="o">=</span> <span class="s1">&#39;/content/pose_resnet_50_256x256.pth.tar&#39;</span>
</code></pre></div>


<p>update the config file</p>
<div class="highlight"><pre><span></span><code><span class="n">update_config</span><span class="p">(</span><span class="n">CONFIG_FILE</span><span class="p">)</span>

<span class="n">config</span><span class="p">.</span><span class="n">GPUS</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span> <span class="o">#</span> <span class="n">we</span> <span class="k">are</span> <span class="n">running</span> <span class="k">on</span> <span class="n">CPU</span>
</code></pre></div>


<p>Now we will load the model</p>
<script src="https://gist.github.com/satyajitghana/2ffae91e4d74b1604c77ba00ae518d5e.js"></script>

<p>We’ll be now using this guy’s image to detect pose. I wonder who this might be 🤔</p>
<p><img alt="yeah this me" src="https://cdn-images-1.medium.com/max/2000/1*c1djEQo2TfSmwcN5Ki9MlA.jpeg">
<div style="text-align: center;">
<em>yeah this me</em>
</div></p>
<p>Time to finally run the model on the image ! (ofcourse doing some image transformations first), you’ll notice something called JOINTS in below code, we’ll use those later ! they are from the MPII dataset, and our model will output those 16 human points points.</p>
<script src="https://gist.github.com/satyajitghana/1ad2256aea0a3ea69137642618ae0179.js"></script>

<p>What now ? Lets do some visualizations !</p>
<script src="https://gist.github.com/satyajitghana/f3c3a98fb569b58dd960d22620c46814.js"></script>

<p><img alt="" src="https://cdn-images-1.medium.com/max/2000/1*Kvw4a639NMIslywaBvB3Aw.png"></p>
<p>Looks Amazing right ! thats Bottom Up HPE approach ! we never detected a bbox for my body, just the 16 parts !</p>
<p><img alt="" src="https://cdn-images-1.medium.com/max/2000/1*PLATFT54cNgrlWqxblMkZQ.png"></p>
<p>What next ? just connect the dot !</p>
<script src="https://gist.github.com/satyajitghana/d2fc95deee416b0d1d8b6c70cd6ea940.js"></script>

<p><img alt="" src="https://cdn-images-1.medium.com/max/2000/1*oqAXPrMKRAtoubD5ursbSQ.png"></p>
<p>It got all the 16 points ! 😲 (you can reduce the THRESHOLD if it didn’t)</p>
<p>But did you notice ? that lady in the back isn’t detected ? that’s because our model was trained on large human images only ! if we were to use a hourglass model kind of architecture, or maybe something like YOLO does for creating different resolution(scales) representations of the image, then we would have detected the pose for that lady as well.</p>
<h2>Converting to ONNX and Quantizing</h2>
<p>What is ONNX ?</p>
<p><img alt="" src="https://cdn-images-1.medium.com/max/2000/1*OZA-la4uErLMTK--xGR6Tg.png"></p>
<p>ONNX is an open format built to represent machine learning models. ONNX defines a common set of operators — the building blocks of machine learning and deep learning models - and a common file format to enable AI developers to use models with a variety of frameworks, tools, runtimes, and compilers.</p>
<p>Install onnx and onnxruntime, we’ll need these</p>
<div class="highlight"><pre><span></span><code><span class="err">! pip install onnx onnxruntime</span>
</code></pre></div>


<script src="https://gist.github.com/satyajitghana/b8007e6174e621de99ec004045eb6677.js"></script>

<div class="highlight"><pre><span></span><code><span class="n">print_size_of_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

<span class="k">Size</span> <span class="p">(</span><span class="n">MB</span><span class="p">):</span> <span class="mi">136</span><span class="p">.</span><span class="mi">326509</span>
</code></pre></div>


<p>Convert it to ONNX !</p>
<p>Also here is a tutorial
<a href="https://pytorch.org/tutorials/advanced/super_resolution_with_onnxruntime.html"><strong>(optional) Exporting a Model from PyTorch to ONNX and Running it using ONNX Runtime - PyTorch…</strong>
<em>In this tutorial, we describe how to convert a model defined in PyTorch into the ONNX format and then run it with ONNX…</em>pytorch.org</a></p>
<script src="https://gist.github.com/satyajitghana/81f56cfc1413b6a260c08bfa12a8fde7.js"></script>

<div class="highlight"><pre><span></span><code><span class="err">Size (MB): 136.247923</span>
</code></pre></div>


<p>Now we’ve successfully converted our model to ONNX</p>
<p>At this point i tried to simply deploy the model to AWS Lambda, but the model size 130MB was too much, it didn’t fit in the 500MB provided.</p>
<h2>Quantize it all !</h2>
<p>A question you might have in your mind is, why not use the PyTorch’s Quantization ?</p>
<p>Well well well, i did take a look at that <a href="https://pytorch.org/tutorials/intermediate/quantized_transfer_learning_tutorial.html">here</a>, the issue being, but take a look at <a href="https://discuss.pytorch.org/t/am-i-correct-in-concluding-that-resnet-that-comes-with-pytorch-cant-be-quantized-by-pytorch/82405">this</a>, TL DR; the models we have right now cannot be quantized, only a few very special models can be like BERT, LSTM, or else you have to modify your model and add some special layers.</p>
<script src="https://gist.github.com/satyajitghana/f093f237e4fa0f28e06b4cebeee8fd4b.js"></script>

<div class="highlight"><pre><span></span><code><span class="err">Size (MB): 65.933789</span>
</code></pre></div>


<p>Did you see that ? the model is half the size now ! although this comes with a caveat that the accuracy is reduced.</p>
<h2>Running the model on ONNX Runtime</h2>
<p>Now we will run the model on python onnx runtime</p>
<script src="https://gist.github.com/satyajitghana/bb80a991b2d48f18c8b33627cabc9ea4.js"></script>

<p><img alt="" src="https://cdn-images-1.medium.com/max/2000/1*ie9HFcP6TIwM16f_jhyhcw.png"></p>
<p>In the Quant Model i lost a hand 😟 maybe reducing threshold might bring it back</p>
<p>But what did i gain from doing all this ?</p>
<p>onnxruntime for cpu is really small, and now i am not dependent upon PyTorch libraries !</p>
<p><img alt="" src="https://cdn-images-1.medium.com/max/2000/1*J7euhcqHjTbmsiztQrCx9Q.png"></p>
<p>Look at the size ! its teeny-tiny for cpu, for my current deployment i was using torch-1.6.0 and torchvision-0.7.0 which took over 500MB uncompressed. something i can’t afford in AWS Lambda free tier. Now that i have the ONNX model and a really small runtime, everything will fit in a single free Lambda runtime !</p>
<p>Plus i have a plan to use onnx.js and run the model on the client side itself ! it’ll save the roundtrips made to Lambda.</p>
<p>Checkout the deployment at: <a href="https://thetensorclan-web.herokuapp.com/">https://thetensorclan-web.herokuapp.com/</a></p>
<p>That’s it Folks ! you now know how simple HPE works ! and how we can convert our PyTorch/Tensorflow/Caffe2 models to ONNX. And how we can then Quantize the model.</p>
<p>Below is the link to the Colab Notebook where all this code is situated, you can play with the data, modify stuff and rerun the notebook
<a href="https://github.com/satyajitghana/TSAI-DeepVision-EVA4.0-Phase-2/blob/master/05-HumanPoseEstimation-ONNX/HumanPoseEstimation_ONNX_Quant.ipynb"><strong>satyajitghana/TSAI-DeepVision-EVA4.0-Phase-2</strong>
<em>Permalink Dismiss GitHub is home to over 50 million developers working together to host and review code, manage…</em>github.com</a></p>
            </section>

            <section class="post-info">
                <div class="post-share">
                    <a class="twitter" href="https://twitter.com/share?text=Human Pose Estimation and Quantization of PyTorch to ONNX Models — A Detailed Guide&amp;url=/2020/08/pose-estimation-onnx.html" onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
                    <i class="ic ic-twitter"></i><span class="hidden">Twitter</span>
                    </a>
                    <a class="facebook" href="https://www.facebook.com/sharer/sharer.php?u=/2020/08/pose-estimation-onnx.html" onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;">
                    <i class="ic ic-facebook"></i><span class="hidden">Facebook</span>
                    </a>
                    <a class="googleplus" href="https://plus.google.com/share?url=/2020/08/pose-estimation-onnx.html" onclick="window.open(this.href, 'google-plus-share', 'width=490,height=530');return false;">
                    <i class="ic ic-googleplus"></i><span class="hidden">Google+</span>
                    </a>
                    <div class="clear"></div>
                </div>

                <aside class="post-tags">
<a href="/tag/hpe">hpe</a><a href="/tag/pytorch">pytorch</a><a href="/tag/onnx">onnx</a><a href="/tag/quantization">quantization</a>                </aside>

                <div class="clear"></div>

                <aside class="post-author">


                        <figure class="post-author-avatar">
                            <img src="/assets/images/avatar.jpg" alt="Satyajit Ghana" />
                        </figure>
                    <div class="post-author-bio">
                        <h4 class="post-author-name"><a href="/author/satyajit-ghana">Satyajit Ghana</a></h4>
                            <p class="post-author-about">ek hee moto: apun ko bohot kuch seekhna hai aur bohot kum waqt mai</p>
                            <span class="post-author-location"><i class="ic ic-location"></i> Bangalore</span>
                            <span class="post-author-website"><a href="http://github.com/satyajitghana"><i class="ic ic-link"></i> Website</a></span>
                        <!-- Social linkes in alphabet order. -->
                            <span class="post-author-github"><a target="_blank" href="https://github.com/satyajitghana"><i class="ic ic-link"></i> GitHub</a></span>
                            <span class="post-author-linkedin"><a target="_blank" href="https://www.linkedin.com/in/satyajitghana"><i class="ic ic-link"></i> LinkedIn</a></span>
                    </div>
                    <div class="clear"></div>
                </aside>

                </section>


                <aside class="post-nav">
                    <a class="post-nav-next" href="/2020/09/intellij-flutter-move-platform.html">
                        <section class="post-nav-teaser">
                            <i class="ic ic-arrow-left"></i>
                                <h2 class="post-nav-title">Moving Intellij-Android-Studio Flutter Projects between Platforms</h2>
                            <p class="post-nav-excerpt">I've faced this problems quite a lot of times, when moving flutter projects between...</p>
                        </section>
                    </a>
                    <a class="post-nav-prev" href="/2020/05/speed-up-training-tpu.html">
                        <section class="post-nav-teaser">
                            <i class="ic ic-arrow-right"></i>
                                <h2 class="post-nav-title">Speed-Up your Model Training w/ TPU on Google Colab</h2>
                            <p class="post-nav-excerpt">In this post we will see how you can leverage using TPU's to speed up training on...</p>
                        </section>
                    </a>
                    <div class="clear"></div>
                </aside>

            </div>
        </article>
    </main>
      <!-- TODO : Body class -->
    <div id="body-class" style="display: none;" class=""></div>

    <footer id="footer">
      <div class="inner">
        <section class="credits">


          <span class="credits-theme">Theme <a href="https://github.com/arulrajnet/attila" rel="nofollow">Attila</a></span>
          <span class="credits-software">Published with <a href="https://github.com/getpelican/pelican" rel="nofollow">Pelican</a></span>
        </section>
      </div>
    </footer>
  </section>

  <script type="text/javascript" src="/theme/js/script.js"></script>

</body>
</html>